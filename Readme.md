## ğŸ§  Telegram AI Chatbot

A lightweight Telegram chatbot powered by an **censored and safe LLaMA-based model** (via Ollama) â€” supports per-user chat history, customizable system prompts, and easy CLI setup.

---

## ğŸ—‚ï¸ Project Structure

```
Telegram_AI_Chatbot-Basic-/
â”œâ”€â”€ main.py                    # Entry point â€“ run this to start the bot
â”œâ”€â”€ requirements.txt           # Required Python dependencies
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py              # Contains the Telegram bot token
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ bot.py                 # Telegram bot logic, message handling, API communication
â”‚   â”œâ”€â”€ model_manager.py       # Ensures the required model is installed in Ollama
â”‚   â””â”€â”€ prompts.py             # Loads system prompts from binary files
â”œâ”€â”€ binary_prompts/
â”‚   â”œâ”€â”€ system_prompt.bin          # Optional system prompt (used with --poetry model)
â””â”€â”€ README.md                  # You are here!
```

---

## âœ… Features

* ğŸš€ Chatbot with LLaMA or Mistral model backend (Ollama)
* ğŸ§  Maintains **chat history per Telegram user session**
* âš™ï¸ CLI system prompt selector (`--model` options)
* ğŸ” Uses local Ollama instance â€” no API key required
* âœ… Safe and censored model flexibility
* âœ‹ `/start` to reset chat
* ğŸ”„ Auto-installs model (if missing) via Ollama CLI

---

## ğŸ§° Requirements

* Python 3.10+
* [Ollama](https://ollama.com/) installed and running
* A Telegram bot token ([get one here](https://t.me/BotFather))
* Recommended model installed: `llama2`

---

## ğŸ Getting Started

### 1. Clone the repo and navigate in:

```bash
git clone <your-repo-url>
cd Telegram_AI_Chatbot-Basic-
```

### 2. Set up a virtual environment:

```bash
python -m venv venv
source venv/bin/activate     # On Linux/macOS
venv\Scripts\activate        # On Windows
```

### 3. Install dependencies:

```bash
pip install -r requirements.txt
```

---

## âš™ï¸ Configuration

### 1: Create a `.env` file in the project root

```env
# .env
TELEGRAM_BOT_TOKEN = "your-telegram-bot-token-here"
ENV_MODEL_NAME = "llama2"
```

### 2. Choose your **model** in `src/model_manager.py` (Automatically chosen, can be changed in .env file):

```python
MODEL_NAME = "llama2"
```

This model will be automatically installed via:

```bash
ollama pull llama2
```

> â„¹ï¸ You can change to another Ollama-compatible model if needed.


## ğŸš¦ Running the Bot

You can launch the bot with a system prompt of your choice:

```bash
python main.py --model 1   # default hardcoded prompt
python main.py --model 2   # loads from system_prompt.bin
```

---

## ğŸ’¬ Telegram Commands

| Command  | Description                         |
| -------- | ----------------------------------- |
| `/start` | Start or reset the conversation     |

---

## ğŸ” Safety Notes

* You are responsible for content generated by models.
* Use a safer model like:

```python
MODEL_NAME = "llama2"
```

These chat-tuned variants are optimized for helpful, safe assistant behavior.

---
